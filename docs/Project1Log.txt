Matthew Hruz
Project 1 Log

8/25/2015
Began looking into the design for Project 1 using tips given in class today. Looked at a few programming languages but eventually decided on Python. Created all the code for Project 0. Learned a little bit of Pascal to get a brief introduction to the language I will be writing a Compiler for.

8/27/2015
Reviewed the handouts. Diagrammed some Finite State Machines on a whiteboard and took pictures of them. 

8/28/2015
The general plan for project 1 is coming together. I plan on making a class for a Finite State Machine, and using it to make FSMs for the different token types.

The functions for the FSM are:
 1) addState(name, handler)
	This function will add a node to the Finite state machine. Name is a string and is the unique identifier for the node. Handler is a function that will handle the transitions to new states, and will output the final result once a token has reached an end state. It should be noted that the class will maintain a list of state names, and if a handler tries to transition to a state name that is not in the class's list of state names at run-time, an error will occur, so it will be important to double check the handlers prior to running.

 2) setStart(name)
	This sets what the start state is. It must be a state that has already been added by add_state()

 3) run(input)
	This will take a bit of input and will start the Finite State Machine. The conditions must be correct for run to execute. If the start state has not yet been set, or none of the nodes is an end state, or even if there are no nodes, an exception will be raised.

 4) isRunning() (optional)
	Returns a boolean value as to whether or not the FSM is running or not. Will add on a need-basis. As of right now this is optional.

The fields for FSM are:
 1) states - A set of states

Currently, main.py has two functions:
	parse() - will eventually handle the parsing of tokens.
	getHelp() - prints a little command-line help info.
There is also a little bit of main function code which does project 0 work

8/30/2015
Wrote code for FSM class. The design has changed a little bit. Took pictures of whiteboard design sketches. Currently, the FSM class works and Relational operators work, but only one token per line is processed (the buffer and pointers haven't been programmed yet).

9/1/2015
I Had to make some changes to the Lexer FSM class. The Finite State machine class should only accept one character at a time, rather than processing one line at a time. The previous way was a nice proof-of-concept that the Finite State machine works, but the lexer obviously can't work in this way. Instead of doing all the work in one call of run(), the lexer FSM will maintain a record of its current state, which is updated with every call to feedChar(char). These were the particular changes to the code:

-removed run(). Migrated code to feedChar(char) and start(optional char)

+added feedChar(char). Takes in a character, passing it into the handler method for the current state. The handler will then be in charge of updating the state in the same manner as before, by returning the name of the next state. feedChar immediately checks the returned state for validity before returning True to indicate that the machine is still executing and waiting for a new state. Also, just as before, if the handler returns a python dictionary type, it is an indication that the token has been determined. feedChar() will terminate the execution of the finite state machine and return the token. If a handler returns NoneType then feedChar knows that the FSM cannot parse the token and returns False to indicate that the token type cannot be determined.

+added start(optional char). Start is similar to the older run() in that it is called to begin execution of the FSM, but in this case it will only check that the FSM is ready to begin accepting states, initalize the FSM's currentState with the startState, and set the new isRunning flag to True. char is an optional parameter that is set to None if no value is passed in. If char is not None, then a call to feedChar(char) is executed at the end of the start(char) method. Start() also resets the machine so a new instance does not need to be created.

Additionally, as it is now more appropriate, i have added an isRunning field and an isRunning() getter method.

This being done, I began planning the buffer. Since python has the luxury of concatenating arrays, I will be using a character array buffer that will add characters to the end of the array as they arrive and will remove characters from the beginning of the array as they are processed by the lexer. In this way the buffer will act more like a FIFO queue.

9/2/2015
Fixed a bug with the buffer. In some circumstances (e.g. the relational operator <=), the token type can be determined without looking ahead to an "other" character. For some reason this was assummed and it was causing issues with the lexical analyzer. Handlers are now in charge of moving the bufferPtr back if they look a character or two too far. I have continued adding each of the different state machines and the code can now iterate through the ordered list until it finds a token. Most of the machines have been implemented.

9/3/2015
The remaining machines have been implemented. Restrictions on the length of the tokens still need to be applied to the machines, and all of the possible lexical errors still need to be coded into the handlers. I also plan on doing some refactoring to make the code more clear, less cluttered, and more efficient.

9/5/2015
There were a few extra machines that I forgot to add. All of the machines are implemented now (for real this time).

9/10/2015
Did some refactoring of the code. Removed the unused isRunning getter method from the Finite State Machine Object.

9/13/2015
Added some real Pascal files (simple Pascal files that are within the language subset we are implementing) to test the lexical analyzer.

9/15/2015
Integrated lexer.py with main.py. Up until this point, I was using test code in lexer.py to test the lexer. Main.py, however, will be handling input and output and will call lexer.py as a module. The code implemented in main.py for "project 0" is now tied in with lexer.py, and the program now outputs a listing file.

9/22/2015
Adding the symbol table (finally). My approach is to create a new python file (symbolTable.py) that will define a symbolTable class. Ideally, I would like to create this class in main.py and pass it into the lexer, but as of right now the lexer will create the symbolTable object and pass it to main.py. This is because I wrote lexer.py as an importable module, and it would take too much time to go back and turn lexer.py into a class.

9/26/2015
Finished the symbol table implementation.

10/3/2015
Fixed a few minor bugs. Made sure that the last token was end of file token.

10/6/2015
Began writing report for project 1.
